{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from os.path import exists\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "json_file = '/mnt/HDD04/WASL Dataset/WLASL-master/start_kit/WLASL_v0.3.json'\n",
    "# txt_file = 'files10.txt'\n",
    "# files_to_process = []\n",
    "\n",
    "with open(json_file) as ipf:\n",
    "    content = json.load(ipf)\n",
    "\n",
    "# file1 = open(txt_file, 'r')\n",
    "# temp = file1.readlines()\n",
    "# files_to_process = [t[:-1] for t in temp]\n",
    "\n",
    "\n",
    "# datapath = '/mnt/HDD04/WASL Dataset/WLASL-master/start_kit/videos/'\n",
    "datapath = '/mnt/HDD04/WASL Dataset/WLASL2000/'\n",
    "vid_savepath = '/mnt/HDD04/WASL Dataset/Scripts/pose_annotated_videos/'\n",
    "annot_path = '/mnt/HDD04/WASL Dataset/Scripts/pose_annotated_images/'\n",
    "skelpath = '/mnt/HDD04/WASL Dataset/Scripts/pose_skeletons/'\n",
    "frame_path = skelpath.replace('pose_skeletons', 'images')\n",
    "json_path = skelpath.replace('pose_skeletons', 'jsons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files present: 21095\n",
      "Num files should be: 21083\n",
      "/mnt/HDD04/WASL Dataset/WLASL2000/23865.mp4\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(datapath + '*mp4')\n",
    "print('Num files present:', len(files))\n",
    "print('Num files should be:', sum([len(c['instances']) for c in content]))\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: book\n",
      "sample: {'bbox': [385, 37, 885, 720], 'fps': 25, 'frame_end': -1, 'frame_start': 1, 'instance_id': 0, 'signer_id': 118, 'source': 'aslbrick', 'split': 'train', 'url': 'http://aslbricks.org/New/ASL-Videos/book.mp4', 'variation_id': 0, 'video_id': '69241'}\n"
     ]
    }
   ],
   "source": [
    "print('Class:', content[0]['gloss'])\n",
    "print('sample:', content[0]['instances'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'69241'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0]['instances'][0]['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing content 5/2000, instance 21/26\n"
     ]
    }
   ],
   "source": [
    "# extract skeleton\n",
    "start_time = time.time()\n",
    "cnt = 0\n",
    "for i, c in enumerate(content):\n",
    "    for j in range(len(c['instances'])):\n",
    "#         if c['instances'][j]['video_id'] not in files_to_process:\n",
    "#             continue\n",
    "        gloss = c['gloss']  # i.e., class \n",
    "        fname = datapath + c['instances'][j]['video_id'] + '.mp4'\n",
    "        \n",
    "        if exists(fname):\n",
    "            cnt += 1\n",
    "            now = time.time()\n",
    "            clear_output(wait=True)\n",
    "            print('Processing content ' + str(i+1) + '/' + str(len(content)) +\n",
    "                  ', instance ' + str(j+1) + '/' + str(len(c['instances'])))\n",
    "            cap = cv2.VideoCapture(fname)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#             start_frame = c['instances'][j]['frame_start'] - 1\n",
    "            start_frame = 0\n",
    "            end_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "#             if c['instances'][j]['frame_end'] != -1:\n",
    "#                 end_frame = c['instances'][j]['frame_end']\n",
    "            subfolder_frame = frame_path + fname.split('/')[-1][:-4]\n",
    "            if not exists(subfolder_frame):\n",
    "                os.mkdir(subfolder_frame)\n",
    "                bbox = c['instances'][j]['bbox']\n",
    "                # extract frames\n",
    "    #             for frame_no in range(start_frame, end_frame + 1):\n",
    "                for frame_no in range(start_frame, end_frame + 1):\n",
    "                    cap.set(1,frame_no)  # Where frame_no is the frame you want\n",
    "                    ret, frame = cap.read()  # Read the frame\n",
    "#                     frame = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "                    cv2.imwrite(subfolder_frame + '/' + fname.split('/')[-1][:-4] + '_frame' + f'{frame_no:05d}' + '.jpg', frame)\n",
    "            \n",
    "            # MediaPipe\n",
    "            subfolder_skel = skelpath + fname.split('/')[-1][:-4]\n",
    "            if not exists(subfolder_skel):\n",
    "                os.mkdir(subfolder_skel)\n",
    "                IMAGE_FILES = sorted(glob.glob(subfolder_frame + '/*jpg'))\n",
    "                with mp_pose.Pose(\n",
    "                    static_image_mode=True,\n",
    "                    model_complexity=2,\n",
    "                    enable_segmentation=True,\n",
    "                    min_detection_confidence=0.5) as pose:\n",
    "\n",
    "                    image = cv2.flip(cv2.imread(IMAGE_FILES[0]), 1)\n",
    "                    fname2 = IMAGE_FILES[0].split('/')[-1]\n",
    "                    prev_results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                    for idx, file in enumerate(IMAGE_FILES):\n",
    "                        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "                        # above).\n",
    "                        image = cv2.flip(cv2.imread(file), 1)\n",
    "                        fname2 = file.split('/')[-1]\n",
    "                        # Convert the BGR image to RGB before processing.\n",
    "                        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                        # Print handedness and draw hand landmarks on the image.\n",
    "    #                     print('Frame: ', idx, '/', len(IMAGE_FILES))\n",
    "                        # print('Handedness:', results.multi_handedness)\n",
    "                        if not results.pose_landmarks:\n",
    "                            if not prev_results.pose_landmarks:\n",
    "                                continue\n",
    "                            else:\n",
    "                                results = prev_results  # to prevent frame elimination due to non-existent hands\n",
    "                        prev_results = results\n",
    "                        image_height, image_width, _ = image.shape\n",
    "                        annotated_image = image.copy()\n",
    "                        data = []\n",
    "#                         print(results.pose_landmarks.landmark)\n",
    "#                         for pose_id, pose_landmarks in enumerate(results.pose_landmarks):\n",
    "\n",
    "\n",
    "                          # print('hand_landmarks:', hand_landmarks)\n",
    "                          # print(\n",
    "                          #     f'Index finger tip coordinates: (',\n",
    "                          #     f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "                          #     f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "                          # )\n",
    "                          # print(dir(hand_landmarks.landmark[0]))\n",
    "                          # print(hand_landmarks.landmark[0])\n",
    "                          # print(hand_landmarks.landmark[0].x)\n",
    "\n",
    "                        for land_id, mark in enumerate(results.pose_landmarks.landmark):\n",
    "\n",
    "                            if land_id == 0:\n",
    "                                x_temp = [mark.x]\n",
    "                                y_temp = [mark.y]\n",
    "                                z_temp = [mark.z]\n",
    "                            else:\n",
    "                                x_temp = np.concatenate((x_temp, [mark.x]), 0)\n",
    "                                y_temp = np.concatenate((y_temp, [mark.y]), 0)\n",
    "                                z_temp = np.concatenate((z_temp, [mark.z]), 0)\n",
    "\n",
    "                        data.append(x_temp)\n",
    "                        data.append(y_temp)\n",
    "                        data.append(z_temp)\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                              annotated_image,\n",
    "                              results.pose_landmarks,\n",
    "                              mp_pose.POSE_CONNECTIONS,\n",
    "                              landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                        \n",
    "                        with open(subfolder_skel + '/' + fname2.replace('jpg', 'txt'), 'w') as f:\n",
    "                            for elem in data:\n",
    "                                for e in elem:\n",
    "                                    f.write(str(e) + ' ')\n",
    "                                f.write('\\n')\n",
    "                        subfolder_im = annot_path + fname.split('/')[-1][:-4]\n",
    "                        if not exists(subfolder_im):\n",
    "                            os.mkdir(subfolder_im)\n",
    "                        cv2.imwrite(subfolder_im + '/' + fname2.replace('jpg', 'png'), cv2.flip(annotated_image, 1))\n",
    "                    \n",
    "                    # create video\n",
    "#                     files = sorted(glob.glob(subfolder_im + '/*png'))\n",
    "#                     frame = cv2.imread(files[0])\n",
    "#                     height, width, layers = frame.shape\n",
    "#                     video_name = vid_savepath + fname.split('/')[-1][:-4] + '.avi'\n",
    "#                     video = cv2.VideoWriter(video_name, 0, fps, (width, height))\n",
    "#                     for image in files:\n",
    "#                         video.write(cv2.imread(image))\n",
    "#                     video.release()\n",
    "                    \n",
    "            print('Elapsed time:', time.time() - now, 'sec')\n",
    "            print('Num. processed file:' + str(cnt) + '/' + str(len(files)))\n",
    "            print('Total Elapsed time:', (time.time() - start_time)/3600, 'hrs')\n",
    "            # save content as json\n",
    "            json_name = json_path + fname.split('/')[-1][:-3] + 'json'\n",
    "            \n",
    "            if not exists(json_name):\n",
    "                content2 = c['instances'][j]\n",
    "                content2['gloss'] = c['gloss']\n",
    "                json_object = json.dumps(content2, indent=4)\n",
    "                # Writing to sample.json\n",
    "                with open(json_name, \"w\") as outfile:\n",
    "                    outfile.write(json_object)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_name) as ipf:\n",
    "    temp_content = json.load(ipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [210, 55, 567, 400],\n",
       " 'fps': 25,\n",
       " 'frame_end': -1,\n",
       " 'frame_start': 1,\n",
       " 'instance_id': 6,\n",
       " 'signer_id': 12,\n",
       " 'source': 'aslsearch',\n",
       " 'split': 'train',\n",
       " 'url': 'http://www.aslsearch.com/signs/videos/whistle.mp4',\n",
       " 'variation_id': 0,\n",
       " 'video_id': '63190',\n",
       " 'gloss': 'whistle'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() takes at least 1 positional argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m----> 3\u001b[0m [\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m()) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m content]\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m----> 3\u001b[0m [\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m content]\n",
      "\u001b[0;31mTypeError\u001b[0m: sum() takes at least 1 positional argument (0 given)"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "[print(sum()) for c in content]\n",
    "# Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(content[0]['instances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
