{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: /mnt/HDD04/WASL Dataset/Scripts/datasets/WLASL_100_skel.pkl\n"
     ]
    }
   ],
   "source": [
    "import glob, h5py, pickle, cv2, re, os\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mat73\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "channels = 3\n",
    "\n",
    "num_class = 100\n",
    "sub = 'WLASL_' + str(num_class) + '_skel'\n",
    "filename = '/mnt/HDD04/WASL Dataset/Scripts/datasets/'+sub+'.pkl'\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num file to process: 2038\n",
      "Num. env files: 10461\n"
     ]
    }
   ],
   "source": [
    "env_path = '/mnt/HDD04/WASL Dataset/Scripts/envelopes_sim/'\n",
    "env_threshold = 2e3\n",
    "vid_path = '/mnt/HDD04/WASL Dataset/WLASL2000/'\n",
    "skel_path = env_path.replace('envelopes_sim', 'skeletons_mat')\n",
    "md_path = env_path.replace('envelopes_sim', 'microDoppler_sim')\n",
    "json_path = env_path.replace('envelopes_sim', 'jsons')\n",
    "proc_file_path = env_path.replace('envelopes_sim/', 'files' + str(num_class) + '.txt')\n",
    "  \n",
    "# removing the new line characters\n",
    "with open(proc_file_path) as f:\n",
    "    proc_files = [line.rstrip() for line in f]\n",
    "print('Num file to process:', len(proc_files))\n",
    "\n",
    "env_files = glob.glob(env_path + '*txt')\n",
    "json_files = glob.glob(json_path + '*json')\n",
    "print('Num. env files:', len(env_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book': 40, 'drink': 35, 'computer': 30, 'go': 26, 'before': 26, 'chair': 26, 'who': 25, 'clothes': 25, 'candy': 24, 'deaf': 23, 'cousin': 23, 'walk': 22, 'year': 22, 'help': 22, 'fine': 22, 'thin': 22, 'no': 22, 'yes': 22, 'all': 21, 'what': 21, 'thanksgiving': 21, 'mother': 21, 'orange': 21, 'finish': 21, 'cool': 21, 'many': 21, 'woman': 21, 'hot': 21, 'now': 21, 'table': 21, 'like': 21, 'black': 21, 'wrong': 20, 'bed': 20, 'blue': 20, 'fish': 20, 'shirt': 20, 'tall': 20, 'can': 20, 'study': 20, 'bowling': 20, 'man': 20, 'dog': 20, 'family': 20, 'hat': 20, 'hearing': 20, 'later': 20, 'white': 20, 'kiss': 20, 'graduate': 20, 'language': 20, 'pizza': 19, 'school': 19, 'eat': 19, 'secretary': 19, 'meet': 19, 'last': 19, 'want': 19, 'doctor': 19, 'dance': 19, 'play': 19, 'corn': 19, 'forget': 19, 'short': 19, 'accident': 19, 'give': 19, 'dark': 19, 'time': 19, 'bird': 19, 'pink': 19, 'color': 19, 'work': 19, 'cow': 19, 'change': 19, 'apple': 19, 'enjoy': 19, 'basketball': 18, 'full': 18, 'birthday': 18, 'wife': 18, 'wait': 18, 'city': 18, 'letter': 18, 'visit': 18, 'decide': 18, 'medicine': 18, 'paint': 18, 'africa': 18, 'same': 18, 'how': 18, 'pull': 18, 'cook': 18, 'purple': 18, 'paper': 18, 'water': 18, 'but': 18, 'jacket': 18, 'tell': 18, 'cheat': 18, 'yellow': 18}\n"
     ]
    }
   ],
   "source": [
    "import itertools, json\n",
    "clas_dict = dict()\n",
    "# for e in json_files:\n",
    "#     #\n",
    "#     fname = e.split('/')[-1]\n",
    "#     underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "#     word_id = fname.find('word')\n",
    "#     clas = fname[word_id+4:underscore_idx[-1]]\n",
    "#     if clas not in clas_dict:\n",
    "#         clas_dict[clas] = 1\n",
    "#     else:\n",
    "#         clas_dict[clas] += 1\n",
    "# sorted_clas_dict = {k: v for k, v in sorted(clas_dict.items(), key=lambda item: item[1])}\n",
    "# reverse =dict(reversed(list(sorted_clas_dict.items())))\n",
    "# with open(json_path) as ipf:\n",
    "#     content = json.load(ipf)\n",
    "\n",
    "for j in json_files:\n",
    "#     gloss = c['gloss']\n",
    "    with open(j) as ipf:\n",
    "        content = json.load(ipf)\n",
    "    if content['gloss'] in clas_dict:\n",
    "        clas_dict[content['gloss']] += 1\n",
    "    else:\n",
    "        clas_dict[content['gloss']] = 1\n",
    "#     for ins in c['instances']:\n",
    "#         if not os.path.exists(env_path + ins['video_id'] + '.txt'):\n",
    "#             continue\n",
    "#         if gloss in clas_dict:\n",
    "#             clas_dict[gloss] += 1\n",
    "#         else:\n",
    "#             clas_dict[gloss] = 1\n",
    "\n",
    "\n",
    "# select the ones with most samples\n",
    "# sorted_clas_dict = dict(itertools.islice(clas_dict.items(), num_class))\n",
    "sorted_clas_dict = dict(sorted(clas_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_clas_dict = dict(itertools.islice(sorted_clas_dict.items(), num_class))\n",
    "print(sorted_clas_dict)\n",
    "select_classes = sorted_clas_dict.keys()\n",
    "# print('select_classes:', select_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_clas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer\n"
     ]
    }
   ],
   "source": [
    "j = json_files[0]\n",
    "with open(json_path + '/12332.json') as ipf:\n",
    "    content = json.load(ipf)\n",
    "    print(content['gloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 0,\n",
       " 'drink': 1,\n",
       " 'computer': 2,\n",
       " 'go': 3,\n",
       " 'before': 4,\n",
       " 'chair': 5,\n",
       " 'who': 6,\n",
       " 'clothes': 7,\n",
       " 'candy': 8,\n",
       " 'deaf': 9,\n",
       " 'cousin': 10,\n",
       " 'walk': 11,\n",
       " 'year': 12,\n",
       " 'help': 13,\n",
       " 'fine': 14,\n",
       " 'thin': 15,\n",
       " 'no': 16,\n",
       " 'yes': 17,\n",
       " 'all': 18,\n",
       " 'what': 19,\n",
       " 'thanksgiving': 20,\n",
       " 'mother': 21,\n",
       " 'orange': 22,\n",
       " 'finish': 23,\n",
       " 'cool': 24,\n",
       " 'many': 25,\n",
       " 'woman': 26,\n",
       " 'hot': 27,\n",
       " 'now': 28,\n",
       " 'table': 29,\n",
       " 'like': 30,\n",
       " 'black': 31,\n",
       " 'wrong': 32,\n",
       " 'bed': 33,\n",
       " 'blue': 34,\n",
       " 'fish': 35,\n",
       " 'shirt': 36,\n",
       " 'tall': 37,\n",
       " 'can': 38,\n",
       " 'study': 39,\n",
       " 'bowling': 40,\n",
       " 'man': 41,\n",
       " 'dog': 42,\n",
       " 'family': 43,\n",
       " 'hat': 44,\n",
       " 'hearing': 45,\n",
       " 'later': 46,\n",
       " 'white': 47,\n",
       " 'kiss': 48,\n",
       " 'graduate': 49,\n",
       " 'language': 50,\n",
       " 'pizza': 51,\n",
       " 'school': 52,\n",
       " 'eat': 53,\n",
       " 'secretary': 54,\n",
       " 'meet': 55,\n",
       " 'last': 56,\n",
       " 'want': 57,\n",
       " 'doctor': 58,\n",
       " 'dance': 59,\n",
       " 'play': 60,\n",
       " 'corn': 61,\n",
       " 'forget': 62,\n",
       " 'short': 63,\n",
       " 'accident': 64,\n",
       " 'give': 65,\n",
       " 'dark': 66,\n",
       " 'time': 67,\n",
       " 'bird': 68,\n",
       " 'pink': 69,\n",
       " 'color': 70,\n",
       " 'work': 71,\n",
       " 'cow': 72,\n",
       " 'change': 73,\n",
       " 'apple': 74,\n",
       " 'enjoy': 75,\n",
       " 'basketball': 76,\n",
       " 'full': 77,\n",
       " 'birthday': 78,\n",
       " 'wife': 79,\n",
       " 'wait': 80,\n",
       " 'city': 81,\n",
       " 'letter': 82,\n",
       " 'visit': 83,\n",
       " 'decide': 84,\n",
       " 'medicine': 85,\n",
       " 'paint': 86,\n",
       " 'africa': 87,\n",
       " 'same': 88,\n",
       " 'how': 89,\n",
       " 'pull': 90,\n",
       " 'cook': 91,\n",
       " 'purple': 92,\n",
       " 'paper': 93,\n",
       " 'water': 94,\n",
       " 'but': 95,\n",
       " 'jacket': 96,\n",
       " 'tell': 97,\n",
       " 'cheat': 98,\n",
       " 'yellow': 99}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = dict()\n",
    "for i in range(len(select_classes)):\n",
    "    new_classes[list(select_classes)[i]] = i \n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return np.array(dataframe.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameCapture(path): \n",
    "      \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "    video_length = int(vidObj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print (\"Number of frames: \", video_length)\n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "    success, frame = vidObj.read() \n",
    "    # checks whether frames were extracted \n",
    "#     success = 1\n",
    "    frames = []\n",
    "    while success: \n",
    "  \n",
    "        resized = cv2.resize(frame, (width,height), interpolation = cv2.INTER_LINEAR)\n",
    "        success, frame = vidObj.read() \n",
    "#         print('Read a new frame: ', success)\n",
    "        frames.append(resized) # .resized(width,height)\n",
    "        count += 1\n",
    "        if (count > (video_length-1)):\n",
    "            break\n",
    "    result = np.array([frames[i] for i in range(len(frames))])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(proc_files, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training file: 1630/1630\n",
      "(1567, 150, 3, 42)\n",
      "(1567, 100)\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_vids = []\n",
    "train_skels = []\n",
    "train_labels = []\n",
    "max_vid_len = 150\n",
    "\n",
    "for i, e in enumerate(train_files):\n",
    "    \n",
    "    fname = e\n",
    "    json_name = json_path + fname + '.json'\n",
    "    with open(json_name) as ipf:\n",
    "        content = json.load(ipf)\n",
    "    \n",
    "    if content['gloss'] not in new_classes:\n",
    "        continue\n",
    "    clas = new_classes[content['gloss']]\n",
    "#     clas = clas_dict[content['gloss']]\n",
    "    \n",
    "#     if clas not in clas_dict:\n",
    "#         print('skipping', clas, i)\n",
    "#         continue\n",
    "        \n",
    "    # read envelope\n",
    "    env_name = env_path + e + '.txt'\n",
    "    if not os.path.exists(env_name):\n",
    "        continue\n",
    "    env = load_file(env_name)\n",
    "    if sum(env[0]) < env_threshold:\n",
    "        continue\n",
    "        \n",
    "    # read video\n",
    "#     vid_name = vid_path + fname.replace('txt', 'avi')\n",
    "#     vid = FrameCapture(vid_name)\n",
    "#     num_frames = vid.shape[0]\n",
    "#     train_vids.append(np.array(vid))\n",
    "    \n",
    "    # read skeleton\n",
    "    skel_name = skel_path + fname + '.mat'\n",
    "    skel = loadmat(skel_name)['hands']\n",
    "    skel = np.transpose(skel, [2, 1, 0])\n",
    "    skel = skel[3:]\n",
    "    \n",
    "    # pad missing frames\n",
    "    if skel.shape[0] < max_vid_len:\n",
    "        skel = np.concatenate([skel, np.tile(np.expand_dims(skel[0], 0), [max_vid_len - skel.shape[0], 1, 1])])\n",
    "    elif skel.shape[0] > max_vid_len:\n",
    "        skel = skel[:max_vid_len]\n",
    "        \n",
    "    train_skels.append(skel)\n",
    "    \n",
    "    # read microDoppler\n",
    "#     md_name = md_path + fname.replace('txt', 'png')\n",
    "#     img = cv2.imread(md_name)\n",
    "#     img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) # resize to (128,128)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Processing training file: '+ str(i+1) + '/' + str(len(train_files)))\n",
    "#     train_images.append(img)\n",
    "    train_labels.append(clas)\n",
    "\n",
    "train_labels = to_categorical(np.array(train_labels), num_class)\n",
    "# train_images = np.swapaxes(np.array(train_images), 1, 2).reshape(len(train_images), width, height, channels)/255.\n",
    "# train_vids = np.array(train_vids, dtype=object)/255.\n",
    "train_skels = np.array(train_skels)\n",
    "# print(train_images.shape)\n",
    "print(train_skels.shape)\n",
    "print(train_labels.shape)\n",
    "# print(train_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max([len(i) for i in train_skels])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training file: 408/408\n",
      "(393, 150, 3, 42)\n",
      "(393, 100)\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "test_vids = []\n",
    "test_skels = []\n",
    "test_labels = []\n",
    "\n",
    "for i, e in enumerate(test_files):\n",
    "    \n",
    "    fname = e\n",
    "    json_name = json_path + fname + '.json'\n",
    "    with open(json_name) as ipf:\n",
    "        content = json.load(ipf)\n",
    "    \n",
    "    if content['gloss'] not in new_classes:\n",
    "        continue\n",
    "    clas = new_classes[content['gloss']]\n",
    "#     clas = clas_dict[content['gloss']]\n",
    "    \n",
    "#     if clas not in clas_dict:\n",
    "#         print('skipping', clas, i)\n",
    "#         continue\n",
    "        \n",
    "    # read envelope\n",
    "    env_name = env_path + e + '.txt'\n",
    "    if not os.path.exists(env_name):\n",
    "        continue\n",
    "    env = load_file(env_name)\n",
    "    if sum(env[0]) < env_threshold:\n",
    "        continue\n",
    "        \n",
    "    # read video\n",
    "#     vid_name = vid_path + fname.replace('txt', 'avi')\n",
    "#     vid = FrameCapture(vid_name)\n",
    "#     num_frames = vid.shape[0]\n",
    "#     test_vids.append(np.array(vid))\n",
    "    \n",
    "    # read skeleton\n",
    "    skel_name = skel_path + fname + '.mat'\n",
    "    skel = loadmat(skel_name)['hands']\n",
    "    skel = np.transpose(skel, [2, 1, 0])\n",
    "    skel = skel[3:]\n",
    "    \n",
    "    # pad missing frames\n",
    "    if skel.shape[0] < max_vid_len:\n",
    "        skel = np.concatenate([skel, np.tile(np.expand_dims(skel[0], 0), [max_vid_len - skel.shape[0], 1, 1])])\n",
    "    elif skel.shape[0] > max_vid_len:\n",
    "        skel = skel[:max_vid_len]\n",
    "    test_skels.append(skel)\n",
    "    \n",
    "    # read microDoppler\n",
    "#     md_name = md_path + fname.replace('txt', 'png')\n",
    "#     img = cv2.imread(md_name)\n",
    "#     img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) # resize to (128,128)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Processing training file: '+ str(i+1) + '/' + str(len(test_files)))\n",
    "#     test_images.append(img)\n",
    "    test_labels.append(clas)\n",
    "\n",
    "test_labels = to_categorical(np.array(test_labels), num_class)\n",
    "# test_images = np.swapaxes(np.array(test_images, dtype=object), 1, 2).reshape(len(test_images), width, height, channels)/255.\n",
    "# test_vids = np.array(test_vids, dtype=object)/255.\n",
    "test_skels = np.array(test_skels)\n",
    "# print(test_images.shape)\n",
    "print(test_skels.shape)\n",
    "print(test_labels.shape)\n",
    "# print(test_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/HDD04/WASL Dataset/Scripts/datasets/WLASL_100_skel.pkl created.\n"
     ]
    }
   ],
   "source": [
    "data = [train_skels, train_labels, \n",
    "        test_skels, test_labels]\n",
    "with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(data, output, pickle.HIGHEST_PROTOCOL)\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
