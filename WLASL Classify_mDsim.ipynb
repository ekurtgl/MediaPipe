{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102\n",
      "True\n",
      "10.2\n",
      "Location: /home/emre/anaconda3/envs/emre_venv/lib/python3.9/site-packages/torch/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emre/anaconda3/envs/emre_venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print('Location:', torch.__file__) # /home/emre/.local/lib/python3.7/site-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size # Optional[Tensor], Union[Tensor, SparseTensor], Optional[Tuple[int, int]], all about data type\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "from torchsummary import summary\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        data = pickle.load(input)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 3, 128, 128)\n",
      "(224,)\n",
      "(56, 3, 128, 128)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "[train_images, train_vids, train_skels, train_labels,\n",
    " test_images, test_vids, test_skels, test_labels] = load_pkl('datasets/WLASL_10_vid_skel_mDsim.pkl')\n",
    "train_images = np.swapaxes(train_images.astype(np.float64), 1, 3)\n",
    "test_images = np.swapaxes(test_images.astype(np.float64), 1, 3)\n",
    "train_labels = np.argmax(train_labels, -1)\n",
    "test_labels = np.argmax(test_labels, -1)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        temp_x = torch.tensor(self.x[idx], dtype=torch.float)\n",
    "        temp_y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "#         self.x = self.x[idx]\n",
    "#         self.y = self.y[idx]\n",
    "#         return self.x[idx], self.y[idx] \n",
    "        return temp_x, temp_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify mD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(torch.from_numpy(train_images), torch.from_numpy(train_labels))\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "testing_data = CustomImageDataset(torch.from_numpy(test_images), torch.from_numpy(test_labels))\n",
    "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 3, 128, 128])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "training_features, training_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {training_features.size()}\")\n",
    "print(f\"Labels batch shape: {training_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 . batch length: 32\n",
      "1 . batch length: 24\n"
     ]
    }
   ],
   "source": [
    "# iterate through the dataset:\n",
    "for i, batch in enumerate(test_loader):\n",
    "    print(f'{i}', '. batch length:', f'{len(batch[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3)\n",
    "        self.fc1 = nn.Linear(14*14*128, 256) # 3 layers: 14*14*128, 4 layers: 6*6*128\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 126, 126]           1,792\n",
      "         MaxPool2d-2           [-1, 64, 63, 63]               0\n",
      "            Conv2d-3          [-1, 128, 61, 61]          73,856\n",
      "         MaxPool2d-4          [-1, 128, 30, 30]               0\n",
      "            Conv2d-5          [-1, 128, 28, 28]         147,584\n",
      "         MaxPool2d-6          [-1, 128, 14, 14]               0\n",
      "            Linear-7                  [-1, 256]       6,422,784\n",
      "           Dropout-8                  [-1, 256]               0\n",
      "            Linear-9                  [-1, 128]          32,896\n",
      "          Dropout-10                  [-1, 128]               0\n",
      "           Linear-11                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 6,680,202\n",
      "Trainable params: 6,680,202\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 15.17\n",
      "Params size (MB): 25.48\n",
      "Estimated Total Size (MB): 40.84\n",
      "----------------------------------------------------------------\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "summary(model, (3, 128, 128))\n",
    "print('device:', device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(prog_bar = True):\n",
    "    \n",
    "    max_test_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_acc = []\n",
    "        test_acc = []\n",
    "        if prog_bar:\n",
    "            pbar = tqdm(train_loader,position=0)\n",
    "        else:\n",
    "            pbar = train_loader\n",
    "            \n",
    "        # train\n",
    "        for data in pbar:\n",
    "            x, labels = data\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            preds = np.argmax(out.cpu().detach().numpy(), -1)\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            acc = np.sum(preds == labels) / len(labels) * 100\n",
    "            train_acc.append(acc)\n",
    "            if prog_bar:\n",
    "                pbar.set_description('Train_acc: '+str(round(acc,2)))\n",
    "                \n",
    "        # test\n",
    "        for data in test_loader:\n",
    "            x, labels = data\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, labels)\n",
    "            preds = np.argmax(out.cpu().detach().numpy(), -1)\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            acc = np.sum(preds == labels) / len(labels) * 100\n",
    "            test_acc.append(acc)\n",
    "            \n",
    "        if np.mean(test_acc) > max_test_acc:\n",
    "            max_test_acc = np.mean(test_acc)\n",
    "            torch.save(model.state_dict(), 'models\\model_cnn_mDsim.pth')\n",
    "        \n",
    "#         lr_scheduler.step(test_loss)\n",
    "        print('Epoch: ', str(epoch+1)+'/'+str(epochs),'| Training Acc: ', round(np.mean(train_acc), 2), '| Testing Acc: ', round(np.mean(test_acc), 2))\n",
    "#         train_losses.append(train_loss)\n",
    "#         test_losses.append(test_loss)\n",
    "\n",
    "        \n",
    "#         if not prog_bar:\n",
    "#             plt.plot(train_losses, label=\"Train Loss\")\n",
    "#             plt.plot(test_losses, label=\"Validation Loss\")\n",
    "#             plt.xlabel(\"# Epoch\")\n",
    "#             plt.ylabel(\"Loss\")\n",
    "#             plt.legend(loc='upper right')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/100 | Training Acc:  10.71 | Testing Acc:  15.62\n",
      "Epoch:  2/100 | Training Acc:  13.39 | Testing Acc:  14.58\n",
      "Epoch:  3/100 | Training Acc:  14.29 | Testing Acc:  15.62\n",
      "Epoch:  4/100 | Training Acc:  17.41 | Testing Acc:  21.88\n",
      "Epoch:  5/100 | Training Acc:  16.52 | Testing Acc:  16.15\n",
      "Epoch:  6/100 | Training Acc:  26.34 | Testing Acc:  8.85\n",
      "Epoch:  7/100 | Training Acc:  23.21 | Testing Acc:  29.69\n",
      "Epoch:  8/100 | Training Acc:  20.09 | Testing Acc:  20.83\n",
      "Epoch:  9/100 | Training Acc:  23.21 | Testing Acc:  25.52\n",
      "Epoch:  10/100 | Training Acc:  28.57 | Testing Acc:  28.65\n",
      "Epoch:  11/100 | Training Acc:  28.12 | Testing Acc:  18.75\n",
      "Epoch:  12/100 | Training Acc:  22.77 | Testing Acc:  20.31\n",
      "Epoch:  13/100 | Training Acc:  25.45 | Testing Acc:  20.83\n",
      "Epoch:  14/100 | Training Acc:  25.45 | Testing Acc:  26.04\n",
      "Epoch:  15/100 | Training Acc:  25.89 | Testing Acc:  25.0\n",
      "Epoch:  16/100 | Training Acc:  26.34 | Testing Acc:  20.83\n",
      "Epoch:  17/100 | Training Acc:  31.25 | Testing Acc:  23.44\n",
      "Epoch:  18/100 | Training Acc:  32.14 | Testing Acc:  21.88\n",
      "Epoch:  19/100 | Training Acc:  29.46 | Testing Acc:  19.27\n",
      "Epoch:  20/100 | Training Acc:  31.25 | Testing Acc:  30.73\n",
      "Epoch:  21/100 | Training Acc:  33.48 | Testing Acc:  21.88\n",
      "Epoch:  22/100 | Training Acc:  31.25 | Testing Acc:  27.6\n",
      "Epoch:  23/100 | Training Acc:  33.48 | Testing Acc:  20.31\n",
      "Epoch:  24/100 | Training Acc:  34.38 | Testing Acc:  17.19\n",
      "Epoch:  25/100 | Training Acc:  36.61 | Testing Acc:  14.58\n",
      "Epoch:  26/100 | Training Acc:  34.82 | Testing Acc:  19.27\n",
      "Epoch:  27/100 | Training Acc:  40.18 | Testing Acc:  21.88\n",
      "Epoch:  28/100 | Training Acc:  37.5 | Testing Acc:  25.52\n",
      "Epoch:  29/100 | Training Acc:  39.73 | Testing Acc:  21.88\n",
      "Epoch:  30/100 | Training Acc:  37.5 | Testing Acc:  14.58\n",
      "Epoch:  31/100 | Training Acc:  36.61 | Testing Acc:  19.27\n",
      "Epoch:  32/100 | Training Acc:  38.39 | Testing Acc:  18.75\n",
      "Epoch:  33/100 | Training Acc:  36.61 | Testing Acc:  19.79\n",
      "Epoch:  34/100 | Training Acc:  44.64 | Testing Acc:  26.56\n",
      "Epoch:  35/100 | Training Acc:  40.18 | Testing Acc:  16.67\n",
      "Epoch:  36/100 | Training Acc:  38.39 | Testing Acc:  19.27\n",
      "Epoch:  37/100 | Training Acc:  43.75 | Testing Acc:  21.88\n",
      "Epoch:  38/100 | Training Acc:  41.07 | Testing Acc:  18.75\n",
      "Epoch:  39/100 | Training Acc:  39.73 | Testing Acc:  18.23\n",
      "Epoch:  40/100 | Training Acc:  43.75 | Testing Acc:  17.71\n",
      "Epoch:  41/100 | Training Acc:  41.52 | Testing Acc:  11.98\n",
      "Epoch:  42/100 | Training Acc:  43.3 | Testing Acc:  15.62\n",
      "Epoch:  43/100 | Training Acc:  42.86 | Testing Acc:  29.17\n",
      "Epoch:  44/100 | Training Acc:  45.09 | Testing Acc:  19.27\n",
      "Epoch:  45/100 | Training Acc:  48.21 | Testing Acc:  20.31\n",
      "Epoch:  46/100 | Training Acc:  44.2 | Testing Acc:  17.19\n",
      "Epoch:  47/100 | Training Acc:  47.32 | Testing Acc:  19.79\n",
      "Epoch:  48/100 | Training Acc:  46.88 | Testing Acc:  20.31\n",
      "Epoch:  49/100 | Training Acc:  48.66 | Testing Acc:  14.58\n",
      "Epoch:  50/100 | Training Acc:  45.98 | Testing Acc:  20.83\n",
      "Epoch:  51/100 | Training Acc:  42.41 | Testing Acc:  20.31\n",
      "Epoch:  52/100 | Training Acc:  43.75 | Testing Acc:  22.92\n",
      "Epoch:  53/100 | Training Acc:  47.77 | Testing Acc:  15.1\n",
      "Epoch:  54/100 | Training Acc:  49.55 | Testing Acc:  20.83\n",
      "Epoch:  55/100 | Training Acc:  48.21 | Testing Acc:  19.27\n",
      "Epoch:  56/100 | Training Acc:  48.21 | Testing Acc:  21.35\n",
      "Epoch:  57/100 | Training Acc:  50.45 | Testing Acc:  19.27\n",
      "Epoch:  58/100 | Training Acc:  50.89 | Testing Acc:  17.19\n",
      "Epoch:  59/100 | Training Acc:  50.89 | Testing Acc:  19.27\n",
      "Epoch:  60/100 | Training Acc:  49.55 | Testing Acc:  16.67\n",
      "Epoch:  61/100 | Training Acc:  50.45 | Testing Acc:  15.62\n",
      "Epoch:  62/100 | Training Acc:  50.89 | Testing Acc:  23.44\n",
      "Epoch:  63/100 | Training Acc:  53.12 | Testing Acc:  23.96\n",
      "Epoch:  64/100 | Training Acc:  52.68 | Testing Acc:  23.44\n",
      "Epoch:  65/100 | Training Acc:  53.57 | Testing Acc:  17.19\n",
      "Epoch:  66/100 | Training Acc:  53.12 | Testing Acc:  18.23\n",
      "Epoch:  67/100 | Training Acc:  50.45 | Testing Acc:  21.88\n",
      "Epoch:  68/100 | Training Acc:  52.23 | Testing Acc:  20.31\n",
      "Epoch:  69/100 | Training Acc:  48.66 | Testing Acc:  20.31\n",
      "Epoch:  70/100 | Training Acc:  51.79 | Testing Acc:  17.19\n",
      "Epoch:  71/100 | Training Acc:  54.46 | Testing Acc:  23.96\n",
      "Epoch:  72/100 | Training Acc:  51.34 | Testing Acc:  23.44\n",
      "Epoch:  73/100 | Training Acc:  53.12 | Testing Acc:  16.67\n",
      "Epoch:  74/100 | Training Acc:  55.8 | Testing Acc:  19.27\n",
      "Epoch:  75/100 | Training Acc:  50.0 | Testing Acc:  19.79\n",
      "Epoch:  76/100 | Training Acc:  48.66 | Testing Acc:  25.0\n",
      "Epoch:  77/100 | Training Acc:  54.46 | Testing Acc:  18.75\n",
      "Epoch:  78/100 | Training Acc:  54.91 | Testing Acc:  20.83\n",
      "Epoch:  79/100 | Training Acc:  54.91 | Testing Acc:  19.79\n",
      "Epoch:  80/100 | Training Acc:  54.46 | Testing Acc:  12.5\n",
      "Epoch:  81/100 | Training Acc:  53.57 | Testing Acc:  16.67\n",
      "Epoch:  82/100 | Training Acc:  54.46 | Testing Acc:  15.1\n",
      "Epoch:  83/100 | Training Acc:  56.25 | Testing Acc:  20.83\n",
      "Epoch:  84/100 | Training Acc:  57.14 | Testing Acc:  22.4\n",
      "Epoch:  85/100 | Training Acc:  54.91 | Testing Acc:  16.67\n",
      "Epoch:  86/100 | Training Acc:  54.46 | Testing Acc:  18.75\n",
      "Epoch:  87/100 | Training Acc:  55.8 | Testing Acc:  21.35\n",
      "Epoch:  88/100 | Training Acc:  54.91 | Testing Acc:  26.56\n",
      "Epoch:  89/100 | Training Acc:  58.04 | Testing Acc:  17.71\n",
      "Epoch:  90/100 | Training Acc:  59.38 | Testing Acc:  20.83\n",
      "Epoch:  91/100 | Training Acc:  57.59 | Testing Acc:  22.4\n",
      "Epoch:  92/100 | Training Acc:  56.25 | Testing Acc:  16.15\n",
      "Epoch:  93/100 | Training Acc:  55.36 | Testing Acc:  22.4\n",
      "Epoch:  94/100 | Training Acc:  58.04 | Testing Acc:  19.79\n",
      "Epoch:  95/100 | Training Acc:  58.04 | Testing Acc:  23.96\n",
      "Epoch:  96/100 | Training Acc:  57.59 | Testing Acc:  23.44\n",
      "Epoch:  97/100 | Training Acc:  59.38 | Testing Acc:  23.44\n",
      "Epoch:  98/100 | Training Acc:  59.38 | Testing Acc:  18.75\n",
      "Epoch:  99/100 | Training Acc:  58.93 | Testing Acc:  17.71\n",
      "Epoch:  100/100 | Training Acc:  58.04 | Testing Acc:  16.15\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train(prog_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_len: 153\n",
      "(224, 3, 128, 128, 153)\n",
      "(56, 3, 128, 128, 153)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = np.max([len(t) for t in train_vids])\n",
    "print('max_seq_len:', max_seq_len)\n",
    "\n",
    "for idx, t in enumerate(train_vids):\n",
    "    num_pad = max_seq_len - len(t)\n",
    "    if num_pad != 0:\n",
    "        last_frame = np.expand_dims(t[-1], 0)\n",
    "        train_vids[idx] = np.concatenate([t, np.tile(last_frame, [num_pad, 1, 1, 1])])\n",
    "train_vids = np.array(list(train_vids)) \n",
    "train_vids = np.swapaxes(train_vids.astype(np.float64), 1, -1)\n",
    "# train_vids = train_vids.reshape(train_vids.shape[0], train_vids.shape[1],\n",
    "#                                 train_vids.shape[2], train_vids.shape[3]*train_vids.shape[4])\n",
    "# [batch_size, channels, height, width, depth].\n",
    "print(train_vids.shape)\n",
    "\n",
    "for idx, t in enumerate(test_vids):\n",
    "    num_pad = max_seq_len - len(t)\n",
    "    if num_pad != 0:\n",
    "        last_frame = np.expand_dims(t[-1], 0)\n",
    "        test_vids[idx] = np.concatenate([t, np.tile(last_frame, [num_pad, 1, 1, 1])])\n",
    "test_vids = np.array(list(test_vids))\n",
    "test_vids = np.swapaxes(test_vids.astype(np.float64), 1, -1)\n",
    "# test_vids = test_vids.reshape(test_vids.shape[0], test_vids.shape[1],\n",
    "#                               test_vids.shape[2], test_vids.shape[3]*test_vids.shape[4])\n",
    "print(test_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(torch.from_numpy(train_vids), torch.from_numpy(train_labels))\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "testing_data = CustomImageDataset(torch.from_numpy(test_vids), torch.from_numpy(test_labels))\n",
    "test_loader = DataLoader(testing_data, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1, 3, 128, 128, 153])\n",
      "Labels batch shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "training_features, training_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {training_features.size()}\")\n",
    "print(f\"Labels batch shape: {training_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2D\n",
    "#         self.conv = nn.Sequential(nn.Conv2d(3, 32, 3),\n",
    "#                                   nn.MaxPool2d(2, 2),\n",
    "                                  \n",
    "#                                   nn.Conv2d(32, 64, 3),\n",
    "#                                   nn.MaxPool2d(2, 2),\n",
    "                                  \n",
    "#                                   nn.Conv2d(64, 128, 3),\n",
    "#                                   nn.MaxPool2d(2, 2)\n",
    "#                                   )\n",
    "        \n",
    "                                  \n",
    "#         self.fc = nn.Sequential(nn.Linear(14*128*2446, 16),\n",
    "#                                 nn.Dropout(0.5),\n",
    "                                \n",
    "#                                 nn.Linear(16, 10)\n",
    "#                                )\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv3d(3, 32, 3),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool3d((2, 2, 2)),\n",
    "                                  \n",
    "                                  nn.Conv3d(32, 64, 3),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool3d((2, 2, 2)),\n",
    "                                  \n",
    "                                  nn.Conv3d(64, 128, 3),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool3d((2, 2, 1)),\n",
    "                                  \n",
    "                                  nn.Conv3d(128, 128, 3),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool3d((2, 2, 1))\n",
    "                                  )\n",
    "        \n",
    "                                  \n",
    "        self.fc = nn.Sequential(nn.LSTM(32, 256, num_layers=1),\n",
    "                                \n",
    "                                nn.Linear(256, 128),\n",
    "                                nn.ReLU(),\n",
    "#                                 nn.Dropout(0.5),\n",
    "                                \n",
    "                                nn.Linear(128, 64),\n",
    "                                nn.ReLU(),\n",
    "#                                 nn.Dropout(0.5),\n",
    "                                \n",
    "                                nn.Linear(64, 10)\n",
    "                               )\n",
    "        \n",
    "#         self.pool = nn.MaxPool3d(2, 2)\n",
    "#         self.conv2 = nn.Conv3d(32, 64, 3)\n",
    "#         self.conv3 = nn.Conv3d(64, 64, 3)\n",
    "        self.lstm = nn.LSTM(32, 128, num_layers=1)\n",
    "        self.fc1 = nn.Linear(589824, 16) # 3 layers: 14*14*128, 4 layers: 6*6*128\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1, -2) # flatten all dimensions except batch\n",
    "#         x = x.view()\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc(x)\n",
    "#         x = self.drop(x)\n",
    "        x, hidden = self.lstm(x)\n",
    "        x = F.relu(self.fc1(torch.flatten(x, 1)))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.drop(x)\n",
    "        x = F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(2)\n",
    "model = CNN3D().to(device)\n",
    "# summary(model, (3, 128, 128, max_seq_len))\n",
    "print('device:', device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/100 | Training Acc:  11.16 | Testing Acc:  5.36\n",
      "Epoch:  2/100 | Training Acc:  8.93 | Testing Acc:  10.71\n",
      "Epoch:  3/100 | Training Acc:  8.93 | Testing Acc:  8.93\n",
      "Epoch:  4/100 | Training Acc:  9.82 | Testing Acc:  12.5\n",
      "Epoch:  5/100 | Training Acc:  11.61 | Testing Acc:  12.5\n",
      "Epoch:  6/100 | Training Acc:  4.02 | Testing Acc:  10.71\n",
      "Epoch:  7/100 | Training Acc:  9.38 | Testing Acc:  7.14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(prog_bar)\u001b[0m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     25\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 8\n",
    "train(prog_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
